Multi-Disciplinary Treatment on the Anthropomorphism of Large Language Models
This retrospective clinical trial aims to better explore the potential of large language models in medicine by comparing the effectiveness of MDT consultations conducted by human doctors with those conducted by large language models.

The main questions to be addressed are:

Does using large language models to conduct anthropomorphic MDT consultations yield better results than using non-anthropomorphic processes? Is there a significant performance gap between MDT consultations conducted by large language models and those conducted by humans? How much greater is the economic benefit of MDT consultations from large language models compared to those conducted by humans?

Retrospectively collect MDT consultation records from the past 20 years in northern Sichuan in China, as well as anonymized patient medical records. Group 1: Different large language models are assigned to act as doctors from different departments and as MDT secretaries to summarize consultations. Group 2: The large language model directly outputs diagnostic and treatment recommendations for patients. Compare the outputs of groups 1 and 2 with human performance retrospectively, score them, and select the best model from each department for a re-evaluation through anthropomorphic MDT consultations, once again comparing them to human results.
Cancer|Respiratory Failure|Heart Diseases|Infections|Pneumonia|Disease
DIAGNOSTIC_TEST: GPT-4o|DIAGNOSTIC_TEST: GPT-4o mini|DIAGNOSTIC_TEST: MedicalGPT|DIAGNOSTIC_TEST: Claude-3.5 Sonnet|DIAGNOSTIC_TEST: Claude 3 Haiku|DIAGNOSTIC_TEST: Real Doctors
Consultation Cost ($), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Consultation Time (min), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Comprehensiveness of the Multi-Disciplinary Treatment Results (Percentage Scale), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Clarity of Multi-Disciplinary Treatment Results (Percentage Scale), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Correctness of Multi-Disciplinary Treatment Results (Percentage Scale), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Cross-Professional Team Collaboration Practice Assessment (CPAT), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Rating Scale for Summarization, From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.|Flesch-Kincaid Readability Test, From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.
Ethical Compliance (Boolean), From Multi-Disciplinary Treatment Process to Multi-Disciplinary Treatment Process until all json fields are output, the time taken by human doctors to record the time using His system generally does not exceed 12 hours.
This retrospective clinical trial aims to better explore the potential of large language models in medicine by comparing the effectiveness of MDT consultations conducted by human doctors with those conducted by large language models.

The main questions to be addressed are:

Does using large language models to conduct anthropomorphic MDT consultations yield better results than using non-anthropomorphic processes? Is there a significant performance gap between MDT consultations conducted by large language models and those conducted by humans? How much greater is the economic benefit of MDT consultations from large language models compared to those conducted by humans?

Retrospectively collect MDT consultation records from the past 20 years in northern Sichuan in China, as well as anonymized patient medical records. Group 1: Different large language models are assigned to act as doctors from different departments and as MDT secretaries to summarize consultations. Group 2: The large language model directly outputs diagnostic and treatment recommendations for patients. Compare the outputs of groups 1 and 2 with human performance retrospectively, score them, and select the best model from each department for a re-evaluation through anthropomorphic MDT consultations, once again comparing them to human results.