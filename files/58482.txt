Predicting Radiological Extranodal Extension in Oropharyngeal Carcinoma Patients Using AI
Development and validation of a model that predicts rENE from radiological imaging using annotated / labeled scans by means of deep learning
Head and Neck Carcinoma
Prediction of rENE as labeled by the radiologist, using the AI model, The performance of the model will be evaluated in terms of discrimination through the Harrell's C-index and the area (AUC) under the receiver operator curve (ROC) in predicting rENE., Baseline
Overall Survival, Percentage of people who are alive five years after their diagnosis., 5 years|Disease Free Survival, Percentage of people whp who are disease free five years after their diagnosis., 5 years
Oropharyngeal squamous cell carcinoma (OPSCC) is a rare cancer (incidence \~700 per year in the Netherlands), originating in the middle part of the throat. In OPSCC, nodal status is an important prognostic factor for survival. In the clinical TNM (tumor node metastases) system, nodal status is mainly defined by the size, number and laterality of nodal metastases. In surgically treated patients the pathological TNM classification includes the presence of pathological extranodal extension (pENE). pENE is a predictor for poor outcome and also an indication for the addition of chemotherapy to postoperative radiation. However, most patients with OPSCC are treated non-surgically by means of radiation or chemoradiation and thus information about pENE is lacking. Recently, extranodal extension on diagnostic imaging has been associated with prognosis in OPSCC patients. It is anticipated that in the near future radiological ENE (rENE) may be included in the cTNM classification system for refinement of outcome prediction in patients with nodal disease. The diagnosis of rENE on radiological imaging is new and not trivial and we hypothesize that Artificial Intelligence (AI) may support the radiologist in detecting rENE. In this study we aim to develop and validate a model that predicts rENE from radiological imaging using annotated / labeled scans by means of deep learning